{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "import cv2\n",
    "from cv2 import imread, imwrite\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_data(data: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Reads input dataframe then return arrays of images and labels\n",
    "    \"\"\"\n",
    "    image_array = np.zeros(shape=(len(data), 48, 48))\n",
    "    image_label = np.array(list(map(int, data['emotion'])))\n",
    "\n",
    "    for i, row in enumerate(data.index):\n",
    "        image = np.fromstring(data.loc[row, 'pixels'], dtype=int, sep=' ')\n",
    "        image = np.reshape(image, (48, 48))\n",
    "        image_array[i] = image\n",
    "\n",
    "    return image_array, image_label\n",
    "\n",
    "def show_img(images: np.ndarray, labels: np.ndarray):\n",
    "    \"\"\"\n",
    "    Visualize images and labels respectively\n",
    "    \"\"\"\n",
    "    _, axarr=plt.subplots(nrows=2, ncols=5, figsize=(18, 9))\n",
    "    axarr=axarr.flatten()\n",
    "    for idx, label in enumerate(labels[:10]):\n",
    "        axarr[idx].imshow(images[idx], cmap='gray')\n",
    "        axarr[idx].set_xticks([])\n",
    "        axarr[idx].set_yticks([])\n",
    "        axarr[idx].set_title(\"Label:{}\".format(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/icml_face_data.csv\")\n",
    "images, labels = parse_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train data: 22967it [00:03, 6725.11it/s]\n",
      "validation data: 5742it [00:00, 7663.92it/s]\n",
      "test data: 7178it [00:00, 8331.89it/s]\n"
     ]
    }
   ],
   "source": [
    "index = 1\n",
    "for image, label in tqdm(zip(X_train, y_train), desc=\"train data\"):\n",
    "    imwrite(f'../data/images/train/{label}/{index}.png', image)\n",
    "    index += 1\n",
    "for image, label in tqdm(zip(X_valid, y_valid), desc=\"validation data\"):\n",
    "    imwrite(f'../data/images/valid/{label}/{index}.png', image)\n",
    "    index += 1\n",
    "for image, label in tqdm(zip(X_test, y_test), desc=\"test data\"):\n",
    "    imwrite(f'../data/images/test/{label}/{index}.png', image)\n",
    "    index += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
